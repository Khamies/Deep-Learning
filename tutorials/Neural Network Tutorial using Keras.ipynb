{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# __Building a Neural Network using Keras__\n",
    "\n",
    "### __By: Waleed Daud__\n",
    "\n",
    "\n",
    "### __ Welcome!!__\n",
    "\n",
    "#### This's an example of a feedforward NN (a normal one), so for more info about other types of NN please go to:\n",
    "\n",
    "##### Convolution NN: https://keras.io/layers/convolutional/\n",
    "##### Recurrent NN: https://keras.io/layers/recurrent/\n",
    "\n",
    "\n",
    "## __Objective: __\n",
    "#### __In this tutorial__ we'll try yo predict if a woman has a breast cancer or not using feedforward neural network.\n",
    "\n",
    "##### Input: features about the women.\n",
    "##### Output: has abreast cancer or not.\n",
    "\n",
    "## __Prerequisite:__\n",
    "#### Basic Understanding of Neural Network.\n",
    "\n",
    "\n",
    "#### __Note:__\n",
    "##### 1/ I'm using python 3. \n",
    "\n",
    "##### 2/ Our Network will have 1 hidden layer and an output layer, of course you can change this setting to add whatever you want from layers and hidden units. \n",
    "\n",
    "##### __let's Begin!!__\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __ Feed Forward Neural Network Diagram__ \n",
    "![alt text ](http://cse22-iiith.vlabs.ac.in/exp4/images/structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; __Image by__ [Lucas Rod√©s-Guirao](https://www.kaggle.com/luikna/eda-and-tensorflow-implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "# Initial Step: Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll find more illustrations about these import statements later !!\n",
    "\n",
    "from keras.models import Sequential            \n",
    "\n",
    "from keras.layers import Dense  \n",
    "\n",
    "from keras.utils import to_categorical              \n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Building our  Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential() # this's the NN algorithm, it's implemented for you,you don't need to code this from scratch\n",
    "                    #but if you want to you're more than welcome!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Adding the layers\n",
    "__ units : Number of units__ <br>\n",
    "__activation : Type of activation fuction__<br>\n",
    "__ input_dim: Number of input features__<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=64, activation='relu', input_dim=30))        # layer one (hidden layer). \n",
    "model.add(Dense(units=2, activation='softmax'))                    # output layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configuring the model for training.\n",
    "\n",
    "__loss: type of loss function__ <br>\n",
    "__optimizer: type of optimization algorithm. (ex: gradient decent)__<br>\n",
    "__metrics: a model metric ,just to help for outputting the accuracy of the model.__<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data=load_breast_cancer()    # loading the data, data usually is a file with an extension .csv ,....... \n",
    "                             # example: breast_cancer.csv \n",
    "                             # then you will use a function to load it, here all this is done by\n",
    "                             # load_breast_cancer() function\n",
    "\n",
    "\n",
    "            \n",
    "X=data.data                  # this's the data (woman's features).\n",
    "y=data.target                # this the label of that data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 3 (Optional but recommended): Splitting the data into two sets: training and testing sets.\n",
    "__We will divide our data to training set: 70% and testing set: 30%__<br><br>\n",
    "__1- test_size: 0.3 means 30%__ <br>\n",
    "__2- random_state: this parameter just to guarantee when you run the code over and over,\n",
    "the data in the two sets will be the same,this's just for an educational purpose, so never mind!!__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the labels to a categorical one.\n",
    "\n",
    "__ In this example, we have two labels 0 or 1 , so each example will have one of thoes labels, so if we can \n",
    "symbolize each one them by a vector :__<br>\n",
    "\n",
    "__ 0 will be [1 0] <br>\n",
    "1 Will be [0 1]__ <br>\n",
    "\n",
    "__so, if we run our model and the result was \"a women has breast cancer\", the first neuron will have a value of  1 and the seocnd will be 0.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = to_categorical(y_train)\n",
    "y_test_binary=to_categorical(y_test)\n",
    "\n",
    "# uncomment this and see the result!!\n",
    "#print(y_train_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training\n",
    "\n",
    "__epochs:__ An epoch is an iteration over the entire x_train and y_train_binary <br>\n",
    "__batch size:__  check the image <br>\n",
    "\n",
    "__batch_size:__\n",
    "\n",
    "__ let's say you have 1050 training samples and you want to set up batch_size equal to 100. Algorithm takes first 100 samples (from 1st to 100th) from the training dataset and trains network. Next it takes second 100 samples (from 101st to 200th) and train network again __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "398/398 [==============================] - 1s 2ms/step - loss: 6.0342 - acc: 0.6256\n",
      "Epoch 2/5\n",
      "398/398 [==============================] - 0s 64us/step - loss: 6.0342 - acc: 0.6256\n",
      "Epoch 3/5\n",
      "398/398 [==============================] - 0s 51us/step - loss: 6.0342 - acc: 0.6256\n",
      "Epoch 4/5\n",
      "398/398 [==============================] - 0s 64us/step - loss: 6.0342 - acc: 0.6256\n",
      "Epoch 5/5\n",
      "398/398 [==============================] - 0s 50us/step - loss: 6.0342 - acc: 0.6256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdd91a8438>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train_binary, epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.predict(x_test, batch_size=128)\n",
    "# uncomment to see the result!!\n",
    "# print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 28us/step\n"
     ]
    }
   ],
   "source": [
    "# Also you can use this function to evaluate the model and print the loss and accuracy, all this in a single line of code.\n",
    "loss_and_metrics = model.evaluate(x_test, y_test_binary, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally: Printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples:  (398, 30)\n",
      "Number of labels:  (398,)\n",
      "Weights of first layer :   <tf.Variable 'dense_107/kernel:0' shape=(30, 64) dtype=float32_ref>\n",
      "Biases first layer :   <tf.Variable 'dense_107/bias:0' shape=(64,) dtype=float32_ref>\n",
      "Weights of second layer :   <tf.Variable 'dense_108/kernel:0' shape=(64, 2) dtype=float32_ref>\n",
      "Biases of second layer :   <tf.Variable 'dense_107/kernel:0' shape=(30, 64) dtype=float32_ref>\n",
      "\n",
      "\n",
      "Final loss or the output of the cost function:  5.938245767738387\n",
      "Model Accuracy:  63.157895329402905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of  training examples: \",x_train.shape[0])\n",
     "print(\"Number of features: \",x_train.shape[1])\n",
    "print(\"Number of training labels: \", y_train.shape[0])\n",
    "print(\"Weights of first layer :  \",model.weights[0])\n",
    "print(\"Biases first layer :  \",model.weights[1])\n",
    "print(\"Weights of second layer :  \",model.weights[2])\n",
    "print(\"Biases of second layer :  \",model.weights[0])\n",
    "print(\"\\n\")\n",
    "print (\"Final loss or the output of the cost function: \",loss_and_metrics[0])\n",
    "accuracy=loss_and_metrics[1]\n",
    "print(\"Model Accuracy: \",accuracy*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Useful resources:__\n",
    "\n",
    "__1/ [Neural Network and Deep learning course by Anderw Ng](https://www.coursera.org/learn/neural-networks-deep-learning)__\n",
    "\n",
    "__2/ [A wonderful illustration of Neural Network by Michael Nielsen  ](http://neuralnetworksanddeeplearning.com/)__\n",
    "\n",
    "__3/ [Keras docs](https://keras.io/)__ \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
